{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.651571Z",
     "start_time": "2025-06-15T06:47:20.646865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from config import VECTORSTORE_PATH, CHUNK_SIZE, CHUNK_OVERLAP\n",
    "import re\n",
    "import os\n",
    "import uuid\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime  # To get the current date for the report\n",
    "\n",
    "# Docx generation\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "# LangChain core\n",
    "from langchain.schema import Document as LangChainDocument\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.evaluation import load_evaluator\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "\n",
    "# Docling & Utilities\n",
    "from docling.document_converter import DocumentConverter\n",
    "from utils.sitemap import get_sitemap_urls"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.658759Z",
     "start_time": "2025-06-15T06:47:20.654601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "# Get OpenAI API key\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY, temperature=0)"
   ],
   "id": "715a32efb0560bac",
   "outputs": [],
   "execution_count": 1168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.679082Z",
     "start_time": "2025-06-15T06:47:20.667628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load once at startup\n",
    "def get_embedding_function(api_key: str = None):\n",
    "    \"\"\"\n",
    "    Returns an OpenAI-compatible embedding function. Uses environment variable if no API key provided.\n",
    "\n",
    "    :param api_key: Optional manual API key override\n",
    "    :return: OpenAIEmbeddings object\n",
    "    \"\"\"\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        raise ValueError(\"OpenAI API key not found. Set OPENAI_API_KEY in .env or pass it directly.\")\n",
    "\n",
    "    return OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        openai_api_key=api_key\n",
    "    )\n",
    "\n",
    "\n",
    "# assign globally\n",
    "embedding_function = get_embedding_function()\n"
   ],
   "id": "7a00c72587095c7a",
   "outputs": [],
   "execution_count": 1169
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Document Conversion and Chunking Pipeline**",
   "id": "ddfae608134a98b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.695040Z",
     "start_time": "2025-06-15T06:47:20.693011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_clean_text_from_docling(file_path: Path) -> str:\n",
    "    \"\"\"\n",
    "    Converts a supported file (PDF, DOCX, CSV, HTML, etc.) to plain cleaned text using Docling.\n",
    "\n",
    "    :param file_path: Path to the file to convert\n",
    "    :return: Cleaned text string\n",
    "    \"\"\"\n",
    "    converter = DocumentConverter()\n",
    "    result = converter.convert(file_path)\n",
    "    text = result.document.export_to_text()\n",
    "\n",
    "    # Optional: clean text\n",
    "    text = re.sub(r'\\n\\s*', ' ', text)  # Remove newlines and leading whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spacing\n",
    "    text = re.sub(r'\\$ (\\d)', r'$\\1', text)\n",
    "    return text"
   ],
   "id": "347b84ff4eed8c73",
   "outputs": [],
   "execution_count": 1170
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Load and Split Document**",
   "id": "191a1420d422b56a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.700339Z",
     "start_time": "2025-06-15T06:47:20.697999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chunk_docling_file(file_path: Path, chunk_size: int = 1000, chunk_overlap: int = 200) -> list:\n",
    "    \"\"\"\n",
    "    Load, clean, and split document content from Docling for embedding.\n",
    "\n",
    "    :param file_path: Path to the file to process\n",
    "    :param chunk_size: Maximum number of characters per chunk\n",
    "    :param chunk_overlap: Number of characters that chunks should overlap\n",
    "    :return: List of langchain Document objects\n",
    "    \"\"\"\n",
    "    raw_text = extract_clean_text_from_docling(file_path)\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    texts = splitter.split_text(raw_text)\n",
    "    return [LangChainDocument(page_content=chunk, metadata={\"source\": str(file_path)}) for chunk in texts]"
   ],
   "id": "757c256ccd70b168",
   "outputs": [],
   "execution_count": 1171
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Split Text Function**",
   "id": "403930a5e7615ab4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.708726Z",
     "start_time": "2025-06-15T06:47:20.706984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_text(text, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP):\n",
    "    \"\"\"\n",
    "    Splits input text into overlapping chunks using global or user-defined parameters.\n",
    "\n",
    "    :param text: The input string to split\n",
    "    :param chunk_size: Max characters per chunk (default from config)\n",
    "    :param chunk_overlap: Overlap between chunks (default from config)\n",
    "    :return: List of chunked text strings\n",
    "    \"\"\"\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_text(text)\n"
   ],
   "id": "9200b7e425c28dc7",
   "outputs": [],
   "execution_count": 1172
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Clean Chunk Text Function**",
   "id": "fbd4d1ab53e99ae0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.716792Z",
     "start_time": "2025-06-15T06:47:20.714999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Improves LLM performance by removing token noise\n",
    "def clean_chunk_text(text):\n",
    "    \"\"\"\n",
    "    Cleans chunk text by removing excessive whitespace and newline artifacts.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\n\\s*', ' ', text)  # Remove newlines and leading whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spacing\n",
    "    text = re.sub(r'\\$ (\\d)', r'$\\1', text)  # Fix formatting like \"$ 5B\" → \"$5B\"\n",
    "    return text"
   ],
   "id": "2c467feb33f1a578",
   "outputs": [],
   "execution_count": 1173
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Convert and Chunk Document Function**",
   "id": "d908f2858d411e13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.724383Z",
     "start_time": "2025-06-15T06:47:20.722878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_and_chunk_docling(file_path: Path) -> list[LangChainDocument]:\n",
    "    raw_text = extract_clean_text_from_docling(file_path)\n",
    "    return chunk_docling_file(file_path)"
   ],
   "id": "3b462f71ce083561",
   "outputs": [],
   "execution_count": 1174
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Deduplicate Chunks Function**",
   "id": "23988fd0fe457d8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.732437Z",
     "start_time": "2025-06-15T06:47:20.730406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def deduplicate_chunks(chunks: list[LangChainDocument]) -> tuple[list[LangChainDocument], list[str]]:\n",
    "    \"\"\"\n",
    "    Deduplicates a list of documents using UUID5-based hashing on content.\n",
    "\n",
    "    :param chunks: List of LangChain Document objects\n",
    "    :return: A tuple containing the list of unique Document objects and their UUIDs\n",
    "    \"\"\"\n",
    "    unique_ids = set()\n",
    "    unique_chunks, final_ids = [], []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, chunk.page_content))\n",
    "        if chunk_id not in unique_ids:\n",
    "            unique_ids.add(chunk_id)\n",
    "            unique_chunks.append(chunk)\n",
    "            final_ids.append(chunk_id)\n",
    "\n",
    "    return unique_chunks, final_ids"
   ],
   "id": "f2678de12a4058ab",
   "outputs": [],
   "execution_count": 1175
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Clean Filename Function**",
   "id": "4cb602d878c56595"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.740060Z",
     "start_time": "2025-06-15T06:47:20.738602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_filename(name):\n",
    "    return re.sub(r'[^a-zA-Z0-9_\\-]', '_', name)"
   ],
   "id": "88db146716481311",
   "outputs": [],
   "execution_count": 1176
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Create Vectorstore Function**",
   "id": "12f77cab41d48bf4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.747877Z",
     "start_time": "2025-06-15T06:47:20.746026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_vectorstore(chunks: list[LangChainDocument], embedding_function, collection_name: str,\n",
    "                       vectorstore_path=VECTORSTORE_PATH):\n",
    "    \"\"\"\n",
    "    Create a persistent Chroma vector store from deduplicated Document chunks.\n",
    "\n",
    "    :param chunks: A list of langchain Document objects (already deduplicated)\n",
    "    :param embedding_function: An OpenAI-compatible embedding function\n",
    "    :param collection_name: Collection name for the vector store\n",
    "    :param vectorstore_path: Path where the vector store will be saved\n",
    "    :return: A Chroma vector store object\n",
    "    \"\"\"\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding_function,\n",
    "        collection_name=clean_filename(collection_name),\n",
    "        persist_directory=vectorstore_path\n",
    "    )\n",
    "    vectorstore.persist()\n",
    "    print(f\"Saved vectorstore for: {collection_name}\")\n",
    "    return vectorstore\n"
   ],
   "id": "eaa43d90d538a515",
   "outputs": [],
   "execution_count": 1177
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Create Vectorstore from Text Function**",
   "id": "c91ad9e1c4fe7b69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.755503Z",
     "start_time": "2025-06-15T06:47:20.753717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_vectorstore_from_texts(text: str, embedding_function, collection_name, vectorstore_path=VECTORSTORE_PATH):\n",
    "    \"\"\"\n",
    "    Splits raw text into chunks, wraps into Documents, and stores them in a vector DB.\n",
    "\n",
    "    :param text: Raw input text\n",
    "    :param embedding_function: Embedding function (should be passed in)\n",
    "    :param collection_name: Name of the vector DB collection\n",
    "    :param vectorstore_path: Storage location\n",
    "    :return: Chroma vectorstore object\n",
    "    \"\"\"\n",
    "    chunks = split_text(text)\n",
    "    documents = [LangChainDocument(page_content=chunk) for chunk in chunks]\n",
    "    return create_vectorstore(documents, embedding_function, collection_name, vectorstore_path)"
   ],
   "id": "c09c131bcd5970b9",
   "outputs": [],
   "execution_count": 1178
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Load Vectorstore Function**",
   "id": "fd28a6d6f7383746"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.763030Z",
     "start_time": "2025-06-15T06:47:20.761469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_vectorstore(collection_name, vectorstore_path=VECTORSTORE_PATH):\n",
    "    embedding_function = get_embedding_function()\n",
    "    return Chroma(\n",
    "        persist_directory=vectorstore_path,\n",
    "        embedding_function=embedding_function,\n",
    "        collection_name=clean_filename(collection_name)\n",
    "    )\n"
   ],
   "id": "43de8d9c3f84fad2",
   "outputs": [],
   "execution_count": 1179
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Load Multiple Vectorstores Function** unfinished\n",
   "id": "eb0e635301ba9a0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.770987Z",
     "start_time": "2025-06-15T06:47:20.769037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_multiple_vectorstores(collection_names: list[str], embedding_function, vectorstore_path=VECTORSTORE_PATH):\n",
    "    \"\"\"\n",
    "    Load multiple Chroma vectorstores and combine them using MultiVectorRetriever.\n",
    "\n",
    "    :param collection_names: List of collection names\n",
    "    :param embedding_function: Embedding function used to create the vectorstores\n",
    "    :param vectorstore_path: Base directory for Chroma persistence\n",
    "    :return: MultiVectorRetriever instance\n",
    "    \"\"\"\n",
    "    retrievers = []\n",
    "    for name in collection_names:\n",
    "        vs = Chroma(\n",
    "            collection_name=name,\n",
    "            persist_directory=vectorstore_path,\n",
    "            embedding_function=embedding_function\n",
    "        )\n",
    "        retrievers.append(vs.as_retriever(search_type=\"mmr\"))  # or \"similarity\"\n",
    "\n",
    "    return MultiVectorRetriever(retrievers=retrievers)"
   ],
   "id": "61fbd9c8025bad6d",
   "outputs": [],
   "execution_count": 1180
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Pipeline from File Function**",
   "id": "8aebbc5f004d7154"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.779026Z",
     "start_time": "2025-06-15T06:47:20.776987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pipeline_from_file_docling(\n",
    "        file_path: Path,\n",
    "        embedding_function,\n",
    "        collection_name: str,\n",
    "        vector_store_path: str = \"db\"\n",
    "):\n",
    "    print(f\"\\nProcessing: {file_path.name}\")\n",
    "\n",
    "    # Step 1: Extract and chunk\n",
    "    chunks = chunk_docling_file(file_path)  # or load_and_split_docling_text\n",
    "    print(f\"Chunks created: {len(chunks)}\")\n",
    "\n",
    "    # Step 2: Deduplicate\n",
    "    unique_chunks, final_ids = deduplicate_chunks(chunks)\n",
    "    print(f\"Unique chunks: {len(unique_chunks)}\")\n",
    "\n",
    "    # Step 3: Create vectorstore\n",
    "\n",
    "    print(f\"{file_path.name}: {len(unique_chunks)} chunks created\")\n",
    "\n",
    "    vectorstore = create_vectorstore(\n",
    "        chunks=unique_chunks,\n",
    "        embedding_function=embedding_function,\n",
    "        collection_name=collection_name,\n",
    "        vectorstore_path=vector_store_path\n",
    "    )\n",
    "\n",
    "    print(f\"Vectorstore created: {collection_name}\")\n",
    "    return vectorstore\n"
   ],
   "id": "c41bdd6a3227cce3",
   "outputs": [],
   "execution_count": 1181
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Batch Pipeline from Files Function**",
   "id": "a8aacd23e9a5c4d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.786987Z",
     "start_time": "2025-06-15T06:47:20.784934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def batch_pipeline_from_files_docling(file_paths: list, embedding_function, vectorstore_path=VECTORSTORE_PATH):\n",
    "    \"\"\"\n",
    "    Batch conversion and vectorstore creation from multiple document files using Docling.\n",
    "\n",
    "    :param file_paths: List of file paths to process\n",
    "    :param embedding_function: Embedding function (OpenAI-compatible)\n",
    "    :param vectorstore_path: Directory to persist Chroma vectorstore\n",
    "    :return: List of (collection_name, status) results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for file_path in file_paths:\n",
    "        file_path = Path(file_path)\n",
    "        collection_name = file_path.stem\n",
    "        try:\n",
    "            vs = pipeline_from_file_docling(\n",
    "                file_path=file_path,\n",
    "                embedding_function=embedding_function,\n",
    "                collection_name=collection_name,\n",
    "                vector_store_path=vectorstore_path\n",
    "            )\n",
    "            results.append((collection_name, \"✅ Success\"))\n",
    "        except Exception as e:\n",
    "            results.append((collection_name, f\"❌ Failed: {e}\"))\n",
    "    return results\n"
   ],
   "id": "f7c404edca0bf6f0",
   "outputs": [],
   "execution_count": 1182
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Retrievers for Vectorstore**",
   "id": "98340f0d2681b78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.794268Z",
     "start_time": "2025-06-15T06:47:20.792739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_mmr_retriever(vectorstore, k=5, lambda_mult=0.5):\n",
    "    \"\"\"\n",
    "    Return a retriever using Maximal Marginal Relevance (MMR) search.\n",
    "\n",
    "    Args:\n",
    "        vectorstore: Your Chroma or LangChain-compatible vector DB\n",
    "        k (int): Top-k documents to return\n",
    "        lambda_mult (float): Relevance-diversity balance. 1.0 = relevance only, 0.0 = diversity only.\n",
    "\n",
    "    Returns:\n",
    "        A configured retriever object\n",
    "    \"\"\"\n",
    "    return vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": k,\n",
    "            \"lambda_mult\": lambda_mult\n",
    "        }\n",
    "    )\n"
   ],
   "id": "4804e4db9a2c8c69",
   "outputs": [],
   "execution_count": 1183
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Query Vectorstore with MMR**\n",
    "\n",
    "\n",
    "#### 📌 Definitions:\n",
    "- **d** — A candidate document or chunk\n",
    "- **q** — The user query\n",
    "- **D** — Set of already selected documents\n",
    "- **λ (lambda)** — Trade-off parameter between relevance and diversity (range: 0 to 1)\n",
    "- **Relevance(d, q)** — Similarity between document `d` and the query `q` (often using cosine similarity)\n",
    "- **Redundancy(d, D)** — Maximum similarity between document `d` and any already selected document in `D`\n",
    "\n",
    "#### 🎯 Tuning λ:\n",
    "- **λ → 1.0**: Focuses on returning the most relevant chunks, even if they are redundant\n",
    "- **λ → 0.0**: Focuses on diversity, returning different perspectives or less similar content\n",
    "- **λ = 0.5**: Balanced trade-off between relevance and novelty\n",
    "\n",
    "MMR is commonly used in **RAG pipelines** to improve the variety and informativeness of context passed to a language model.\n"
   ],
   "id": "3f4e5e5705626b57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.802180Z",
     "start_time": "2025-06-15T06:47:20.800353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def query_vectorstore_mmr(query, vectorstore, k=5, lambda_mult=0.5):\n",
    "    \"\"\"\n",
    "    Retrieve top-k diverse and relevant chunks using Maximal Marginal Relevance (MMR).\n",
    "\n",
    "    Args:\n",
    "        query (str): User query\n",
    "        vectorstore: Chroma or other vector DB loaded with documents\n",
    "        k (int): Number of top results to return\n",
    "        lambda_mult (float): Balance between relevance (1.0) and diversity (0.0). Default = 0.5\n",
    "\n",
    "    Returns:\n",
    "        List of relevant text chunks\n",
    "    \"\"\"\n",
    "    retriever = get_mmr_retriever(vectorstore, k=k, lambda_mult=lambda_mult)\n",
    "    raw_results = retriever.get_relevant_documents(query)\n",
    "\n",
    "    return [doc.page_content for doc in raw_results]\n"
   ],
   "id": "7eb7efa083b06dec",
   "outputs": [],
   "execution_count": 1184
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5f650bedbc31c15c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testing retrieving relevant chunks\n",
   "id": "693c13c0f2c5307c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 🧠 Query Intent Classification Integration\n",
    "\n",
    "### High-Level Overview\n",
    "We improved our query handling system by integrating automatic **intent classification**. This allows the LLM to intelligently detect what kind of response the user expects — whether it's a **summary**, a **direct answer**, **data extraction**, or a **news check** — and adapt the output accordingly. This removes the need for hardcoded `if-else` logic and makes the assistant more flexible and intelligent.\n",
    "\n",
    "### Low-Level Breakdown\n",
    "- Introduced a new **intent classification function** using an LLM and a structured system prompt.\n",
    "- The `classify_query_intent()` function feeds the query into a prompt asking the model to return one of four options: `summary`, `specific_question`, `data_extraction`, or `news_check`.\n",
    "- This prompt was previously defined as a global variable; we refactored it into a reusable **function-based format**, making it more modular and easier to move (e.g., into a `config.py` file).\n",
    "- The `respond_to_query()` function now uses this classified intent to route the query to the appropriate **LangChain prompt template**, ensuring the output matches the user's expectations."
   ],
   "id": "153c510ff571bbe4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:20.813210Z",
     "start_time": "2025-06-15T06:47:20.808145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def intent_prompt():\n",
    "    return ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are an intent classifier for a competitive intelligence system. Determine what kind of response the user is expecting from the query below.\n",
    "\n",
    "    Options:\n",
    "    - summary\n",
    "    - specific_question\n",
    "    - data_extraction\n",
    "\n",
    "    Query: {query}\n",
    "\n",
    "    Respond with only one of the options above.\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "# This is conceptual, you'll need to adapt it to your actual classify_query_intent function.\n",
    "# It assumes a similar structure to other prompt templates you might be using.\n",
    "\n",
    "def classify_query_intent(query, llm):\n",
    "    # This is a conceptual prompt for the LLM that performs classification\n",
    "    classification_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "        You are an intelligent router that classifies user queries into specific intents.\n",
    "        The possible intents are: 'summary', 'specific_question', 'data_extraction'.\n",
    "\n",
    "        'summary': Use if the user wants a broad overview or general summary of the document.\n",
    "        'specific_question': Use if the user is asking a direct, factual question that can be answered concisely.\n",
    "        'data_extraction': Use if the user is asking for specific, structured information that can be extracted into sections,\n",
    "                           like an 'executive summary', 'key takeaways', 'financial highlights', 'company overview', 'product lines', etc.\n",
    "\n",
    "        Return only the intent word.\n",
    "        \"\"\"),\n",
    "        (\"human\", \"Query: {query}\\nIntent:\")\n",
    "    ])\n",
    "\n",
    "    # Chain the classification prompt with the LLM\n",
    "    classification_chain = classification_prompt | llm\n",
    "\n",
    "    # Invoke the chain\n",
    "    response = classification_chain.invoke({\"query\": query}).content.strip().lower()\n",
    "\n",
    "    # Basic error handling/fallback\n",
    "    if \"data_extraction\" in response:\n",
    "        return \"data_extraction\"\n",
    "    elif \"summary\" in response:\n",
    "        return \"summary\"\n",
    "    elif \"specific_question\" in response:\n",
    "        return \"specific_question\"\n",
    "    else:\n",
    "        return \"specific_question\" # Default fallback\n",
    "\n",
    "\n",
    "# def respond_to_query(vectorstore, query, llm, k=5, lambda_mult=0.5):\n",
    "#     \"\"\"\n",
    "#     Responds to the user query using MMR-based document retrieval and an LLM.\n",
    "#\n",
    "#     Detects query intent and routes to the appropriate response format:\n",
    "#     - summary: strategic overview\n",
    "#     - specific_question: direct answer\n",
    "#\n",
    "#     Args:\n",
    "#         vectorstore: Chroma vector DB\n",
    "#         query (str): The user’s input or question\n",
    "#         llm: An OpenAI-compatible language model\n",
    "#         k (int): Number of top docs to retrieve\n",
    "#         lambda_mult (float): Relevance-diversity tradeoff for MMR\n",
    "#\n",
    "#     Returns:\n",
    "#         str: The LLM’s response\n",
    "#     \"\"\"\n",
    "#     # Step 1: Detect intent\n",
    "#     intent = classify_query_intent(query, llm)\n",
    "#     print(f\"🔍 Detected intent: {intent}\")\n",
    "#\n",
    "#     # Step 2: Retrieve relevant chunks\n",
    "#     chunks = query_vectorstore_mmr(query, vectorstore, k=k, lambda_mult=lambda_mult)\n",
    "#     context = \"\\n\\n\".join(chunks)\n",
    "#\n",
    "#     # Step 3: Route to proper prompt\n",
    "#     prompt_map = {\n",
    "#         \"summary\": ChatPromptTemplate.from_template(\"\"\"\n",
    "#             You are a competitive intelligence analyst. Based on the following context, write a strategic summary.\n",
    "#             Focus on company background, products, and key insights.\n",
    "#\n",
    "#             Context:\n",
    "#             {context}\n",
    "#         \"\"\"),\n",
    "#         \"specific_question\": ChatPromptTemplate.from_template(\"\"\"\n",
    "#             You are a helpful research assistant. Use the context to directly and concisely answer the user’s question.\n",
    "#\n",
    "#             User question: {query}\n",
    "#             Context:\n",
    "#             {context}\n",
    "#         \"\"\"),\n",
    "#         # Add more routing options as needed\n",
    "#     }\n",
    "#\n",
    "#     prompt = prompt_map.get(intent, prompt_map[\"specific_question\"])\n",
    "#     chain = prompt | llm\n",
    "#\n",
    "#     if intent == \"summary\":\n",
    "#         return chain.invoke({\"context\": context}).content\n",
    "#     else:\n",
    "#         return chain.invoke({\"context\": context, \"query\": query}).content\n",
    "\n",
    "\n",
    "def respond_to_query(vectorstore, query, llm, k=5, lambda_mult=0.5):\n",
    "    \"\"\"\n",
    "    Responds to the user query using MMR-based document retrieval and an LLM.\n",
    "\n",
    "    Detects query intent and routes to the appropriate response format:\n",
    "    - summary: strategic overview\n",
    "    - specific_question: direct answer\n",
    "    - data_extraction: extracts specific data points or sections\n",
    "\n",
    "    Args:\n",
    "        vectorstore: Chroma vector DB\n",
    "        query (str): The user’s input or question\n",
    "        llm: An OpenAI-compatible language model\n",
    "        k (int): Number of top docs to retrieve\n",
    "        lambda_mult (float): Relevance-diversity tradeoff for MMR\n",
    "\n",
    "    Returns:\n",
    "        str: The LLM’s response\n",
    "    \"\"\"\n",
    "    # Step 1: Detect intent\n",
    "    intent = classify_query_intent(query, llm)\n",
    "    print(f\"🔍 Detected intent: {intent}\")\n",
    "\n",
    "    # Step 2: Retrieve relevant chunks\n",
    "    chunks = query_vectorstore_mmr(query, vectorstore, k=k, lambda_mult=lambda_mult)\n",
    "    context = \"\\n\\n\".join(chunks)\n",
    "\n",
    "    # Step 3: Route to proper prompt\n",
    "    prompt_map = {\n",
    "        \"summary\": ChatPromptTemplate.from_template(\"\"\"\n",
    "            You are a competitive intelligence analyst. Based on the following context, write a strategic summary.\n",
    "            Focus on company background (use company name), products, and key insights.\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "        \"\"\"),\n",
    "        \"specific_question\": ChatPromptTemplate.from_template(\"\"\"\n",
    "            You are a helpful research assistant. Use the context to directly and concisely answer the user’s question.\n",
    "\n",
    "            User question: {query}\n",
    "            Context:\n",
    "            {context}\n",
    "        \"\"\"),\n",
    "        \"data_extraction\": ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are an expert data extractor. From the provided context, extract the information requested by the user.\n",
    "\n",
    "        **Output Instructions:**\n",
    "        -   **Format:** Provide the output as plain text. Do NOT use any Markdown formatting (e.g., no bolding with **, no headings with ###, no bullet points with - or * or numbers).\n",
    "        -   **Paragraphs:** Keep paragraphs short and concise, typically 2-4 sentences long.\n",
    "        -   **Content:** Only provide the extracted information. Do NOT include any conversational filler, introductory phrases, or concluding remarks.\n",
    "        -   **Use Company Name:** If the query asks for company background, include the company name from the context.\n",
    "\n",
    "        User request: {query}\n",
    "        Context:\n",
    "        {context}\n",
    "    \"\"\")\n",
    "        # Add more routing options as needed\n",
    "    }\n",
    "\n",
    "    prompt = prompt_map.get(intent, prompt_map[\"specific_question\"])\n",
    "    chain = prompt | llm\n",
    "\n",
    "    if intent == \"summary\":\n",
    "        return chain.invoke({\"context\": context}).content\n",
    "    elif intent == \"data_extraction\":\n",
    "        return chain.invoke({\"context\": context, \"query\": query}).content # Use query for data extraction too\n",
    "    else: # specific_question and any unhandled intents\n",
    "        return chain.invoke({\"context\": context, \"query\": query}).content"
   ],
   "id": "c771d19bc4cb22e1",
   "outputs": [],
   "execution_count": 1185
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Cosine Similarity Test**",
   "id": "de46e0f3261d17ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:21.277831Z",
     "start_time": "2025-06-15T06:47:20.819446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "\n",
    "similarity = cosine_similarity(embedding_function.embed_query(\"cat\"), embedding_function.embed_query(\"dog\"))\n",
    "print(\"Cosine Similarity:\", similarity)"
   ],
   "id": "43533ca82c96c889",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.862957645542653\n"
     ]
    }
   ],
   "execution_count": 1186
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Testing Single File Input**",
   "id": "e3b54cbd1d84fd0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:33.828700Z",
     "start_time": "2025-06-15T06:47:21.289525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file = Path(\"/Users/ralstonraphael/Desktop/flash-report-generator/ingestion/pdf_data/2025-q1-earnings-transcript.pdf\")\n",
    "vectorstore = pipeline_from_file_docling(file, embedding_function, \"earnings_2025_q1\")\n",
    "summary = respond_to_query(\n",
    "    vectorstore,\n",
    "    query=\"what company is this about?\",\n",
    "    llm=llm\n",
    ")\n",
    "print(summary)"
   ],
   "id": "402a96cb7b2231ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 2025-q1-earnings-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter `strict_text` has been deprecated and will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created: 64\n",
      "Unique chunks: 64\n",
      "2025-q1-earnings-transcript.pdf: 64 chunks created\n",
      "Saved vectorstore for: earnings_2025_q1\n",
      "Vectorstore created: earnings_2025_q1\n",
      "🔍 Detected intent: specific_question\n",
      "The company being discussed is Google, as indicated by the mention of Sundar Pichai, who is the CEO of Google.\n"
     ]
    }
   ],
   "execution_count": 1187
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Testing Batch File Inputs**",
   "id": "3a355a999c4fda6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:44.834901Z",
     "start_time": "2025-06-15T06:47:33.845760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_paths = [\n",
    "    Path(\"/Users/ralstonraphael/Desktop/flash-report-generator/ingestion/csv_data/alphabet_full_profile.csv\"),\n",
    "    Path(\"/Users/ralstonraphael/Desktop/flash-report-generator/ingestion/docx_data/alphabet_ai_losses_article.docx\"),\n",
    "    Path(\"/Users/ralstonraphael/Desktop/flash-report-generator/ingestion/pdf_data/2025-q1-earnings-transcript.pdf\")\n",
    "]\n",
    "\n",
    "results = batch_pipeline_from_files_docling(file_paths, embedding_function)\n",
    "\n",
    "for name, status in results:\n",
    "    print(f\"{name}: {status}\")"
   ],
   "id": "d6bb8c315cec515c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter `strict_text` has been deprecated and will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: alphabet_full_profile.csv\n",
      "Chunks created: 2\n",
      "Unique chunks: 2\n",
      "alphabet_full_profile.csv: 2 chunks created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter `strict_text` has been deprecated and will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved vectorstore for: alphabet_full_profile\n",
      "Vectorstore created: alphabet_full_profile\n",
      "\n",
      "Processing: alphabet_ai_losses_article.docx\n",
      "Chunks created: 3\n",
      "Unique chunks: 3\n",
      "alphabet_ai_losses_article.docx: 3 chunks created\n",
      "Saved vectorstore for: alphabet_ai_losses_article\n",
      "Vectorstore created: alphabet_ai_losses_article\n",
      "\n",
      "Processing: 2025-q1-earnings-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter `strict_text` has been deprecated and will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created: 64\n",
      "Unique chunks: 64\n",
      "2025-q1-earnings-transcript.pdf: 64 chunks created\n",
      "Saved vectorstore for: 2025-q1-earnings-transcript\n",
      "Vectorstore created: 2025-q1-earnings-transcript\n",
      "alphabet_full_profile: ✅ Success\n",
      "alphabet_ai_losses_article: ✅ Success\n",
      "2025-q1-earnings-transcript: ✅ Success\n"
     ]
    }
   ],
   "execution_count": 1188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:44.847348Z",
     "start_time": "2025-06-15T06:47:44.846035Z"
    }
   },
   "cell_type": "code",
   "source": "#Pydantic model for structured response",
   "id": "920601e5a7578d8c",
   "outputs": [],
   "execution_count": 1189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:44.862186Z",
     "start_time": "2025-06-15T06:47:44.853525Z"
    }
   },
   "cell_type": "code",
   "source": "vs = load_vectorstore(collection_name=\"2025-q1-earnings-transcript\")\n",
   "id": "702c083be6427827",
   "outputs": [],
   "execution_count": 1190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:44.869308Z",
     "start_time": "2025-06-15T06:47:44.868095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# summary = respond_to_query(vs, query=\"Generate a Flash report of this company\", llm=llm)\n",
    "# print(summary)\n"
   ],
   "id": "feaf5e41944515bd",
   "outputs": [],
   "execution_count": 1191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:52.458575Z",
     "start_time": "2025-06-15T06:47:44.875146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the vectorstore (assuming 'vs' is already loaded from previous cells for '2025-q1-earnings-transcript')\n",
    "# If not, ensure it's loaded:\n",
    "# vs = load_vectorstore(collection_name=\"2025-q1-earnings-transcript\")\n",
    "\n",
    "print(\"--- Extracting Report Sections ---\")\n",
    "\n",
    "executive_summary = respond_to_query(\n",
    "    vs,\n",
    "    query=\"Provide a concise executive summary of the company's performance, focusing on overall results, key business changes, and outlook.\",\n",
    "    llm=llm\n",
    ")\n",
    "print(f\"\\nExecutive Summary:\\n{executive_summary}\\n\")\n",
    "\n",
    "key_takeaways = respond_to_query(\n",
    "    vs,\n",
    "    query=\"List the key takeaways and important strategic points from the document\",\n",
    "    llm=llm\n",
    ")\n",
    "print(f\"\\nKey Takeaways:\\n{key_takeaways}\\n\")\n",
    "\n",
    "\n",
    "financial_highlights = respond_to_query(\n",
    "    vs,\n",
    "    query=\"Summarize the main financial highlights and important figures, including revenues, profits, and cash flow.\",\n",
    "    llm=llm\n",
    ")\n",
    "print(f\"\\nFinancial Highlights:\\n{financial_highlights}\\n\")\n",
    "\n",
    "# Prepare data for the report\n",
    "report_title = \"Q1-2025 Norstella Quarterly Market Participant Update\" # You might extract this dynamically too\n",
    "report_date = datetime.date.today().strftime(\"%B %d, %Y\") # Gets current date\n",
    "\n",
    "report_data = {\n",
    "    \"report_title\": report_title,\n",
    "    \"report_date\": report_date,\n",
    "    \"executive_summary\": executive_summary,\n",
    "    \"key_takeaways\": key_takeaways,\n",
    "    \"financial_highlights\": financial_highlights,\n",
    "}\n",
    "\n",
    "# Generate the DOCX report\n",
    "print(\"\\n--- Generating DOCX Report ---\")"
   ],
   "id": "911ecd1cea1f4f2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Extracting Report Sections ---\n",
      "🔍 Detected intent: data_extraction\n",
      "\n",
      "Executive Summary:\n",
      "The company's performance has shown strong demand, particularly in Google Cloud, where customer demand has consistently outstripped capacity. To address this, the company is focused on ramping up its capabilities to meet customer needs while continuing to invest in long-term innovation. Recent strategic changes include the consolidation of teams, which enhances efficiency and accelerates the speed of bringing products to market. Overall, the company is committed to driving productivity and innovation responsibly, as reflected in its ongoing results.\n",
      "\n",
      "🔍 Detected intent: data_extraction\n",
      "\n",
      "Key Takeaways:\n",
      "In Q1, Google experienced broad-based strength across various ad verticals, with Finance leading due to strong performance in Insurance. Retail, Healthcare, and Travel also contributed significantly to growth. For Q2, it is too early to make definitive comments, but potential impacts from the macro environment are acknowledged, particularly regarding changes to the de minimis exemption, which may create a slight headwind for the ads business in 2025, especially for APAC-based retailers. Google emphasizes its experience in navigating uncertain times and focuses on providing customers with insights into changing consumer behavior, including auction dynamics and query trend insights.\n",
      "\n",
      "🔍 Detected intent: data_extraction\n",
      "\n",
      "Financial Highlights:\n",
      "Net income increased 46% to $34.5 billion, with earnings per share rising 49% to $2.81. Free cash flow was $19 billion for the first quarter and $74.9 billion for the trailing twelve months. The company ended the quarter with $95 billion in cash and marketable securities. Google Services revenues grew 10% to $77.3 billion, driven by a 10% increase in Google Search and Other advertising revenues to $50.7 billion, and a 10% rise in YouTube advertising revenues. Other income and expenses amounted to $11.2 billion, mainly due to an unrealized gain on non-marketable equity securities. Depreciation expenses were just over $1 billion.\n",
      "\n",
      "\n",
      "--- Generating DOCX Report ---\n"
     ]
    }
   ],
   "execution_count": 1192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:52.470107Z",
     "start_time": "2025-06-15T06:47:52.465411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_flash_report(data: dict, output_filename=\"Norstella_Flash_Report.docx\"):\n",
    "    \"\"\"\n",
    "    Generates a Flash Report in DOCX format based on the provided data.\n",
    "\n",
    "    Args:\n",
    "        data (dict): A dictionary containing the extracted information.\n",
    "                     Expected keys:\n",
    "                     - \"executive_summary\": str\n",
    "                     - \"key_takeaways\": list of str or single str\n",
    "                     - \"financial_highlights\": list of str or single str\n",
    "                     - \"report_title\": str (e.g., \"Q4-24 Norstella Quarterly Market Participant Update\")\n",
    "                     - \"report_date\": str (e.g., \"February 19th, 2025\")\n",
    "        output_filename (str): The name of the output DOCX file.\n",
    "    \"\"\"\n",
    "    document = Document()\n",
    "\n",
    "    # --- Header (Simple text for now) ---\n",
    "    section = document.sections[0]\n",
    "    header = section.header\n",
    "    # Ensure there's at least one paragraph in the header\n",
    "    if not header.paragraphs:\n",
    "        header.add_paragraph()\n",
    "    paragraph = header.paragraphs[0]\n",
    "    header_run = paragraph.add_run(\"Norstella\")\n",
    "    header_run.font.size = Pt(12)\n",
    "    header_run.bold = True\n",
    "    paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT\n",
    "\n",
    "    # --- Main Content ---\n",
    "\n",
    "    # Add Report Title\n",
    "    title_paragraph = document.add_paragraph()\n",
    "    title_run = title_paragraph.add_run(data.get(\"report_title\", \"Quarterly Market Participant Update\"))\n",
    "    title_run.font.size = Pt(24)\n",
    "    title_run.bold = True\n",
    "    title_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    document.add_paragraph(f\"Report Date: {data.get('report_date', 'Date Not Available')}\", style='Intense Quote')\n",
    "\n",
    "\n",
    "    # Add Executive Summary\n",
    "    document.add_heading(\"EXECUTIVE SUMMARY\", level=1)\n",
    "    executive_summary_text = data.get(\"executive_summary\", \"Executive summary not available.\")\n",
    "    # Remove common boilerplate if present\n",
    "    executive_summary_text = re.sub(r'### Strategic Summary.*?(Company Background:.*?)?|\\*\\*Company Background:\\*\\*', '', executive_summary_text, flags=re.DOTALL | re.IGNORECASE).strip()\n",
    "    executive_summary_text = re.sub(r'\\*\\*Products:.*|\\*\\*Key Insights:.*', '', executive_summary_text, flags=re.DOTALL | re.IGNORECASE).strip()\n",
    "\n",
    "    document.add_paragraph(executive_summary_text)\n",
    "\n",
    "    # Helper function to add bullet points, cleaning up LLM boilerplate\n",
    "    def add_bullet_points(doc, heading_text, content_key):\n",
    "        doc.add_heading(heading_text, level=1)\n",
    "        content = data.get(content_key)\n",
    "        if content:\n",
    "            if isinstance(content, str):\n",
    "                # Remove common boilerplate from list items\n",
    "                content = re.sub(r'### Strategic Summary.*?(Company Background:.*?)?|\\*\\*Company Background:\\*\\*', '', content, flags=re.DOTALL | re.IGNORECASE).strip()\n",
    "                content = re.sub(r'\\*\\*Products:.*|\\*\\*Key Insights:.*', '', content, flags=re.DOTALL | re.IGNORECASE).strip()\n",
    "\n",
    "                # Split by newlines, handling numbered lists or bullet points\n",
    "                points = [p.strip() for p in content.split('\\n') if p.strip()]\n",
    "                # Refine splitting for numbered lists (e.g., \"1. Point\") or leading bullets\n",
    "                cleaned_points = []\n",
    "                for point in points:\n",
    "                    # Remove leading numbers/bullets like \"1. \", \"- \", \"* \"\n",
    "                    point = re.sub(r'^\\s*[\\d\\*\\-]+\\s*', '', point).strip()\n",
    "                    if point: # Only add if not empty after stripping\n",
    "                        cleaned_points.append(point)\n",
    "\n",
    "                if not cleaned_points: # Fallback if splitting didn't yield points\n",
    "                    doc.add_paragraph(content)\n",
    "                else:\n",
    "                    for point in cleaned_points:\n",
    "                        doc.add_paragraph(point, style='List Bullet')\n",
    "            elif isinstance(content, list):\n",
    "                for item in content:\n",
    "                    doc.add_paragraph(item, style='List Bullet')\n",
    "        else:\n",
    "            doc.add_paragraph(f\"{heading_text.lower().replace('highlights', 'information').replace('key ', '')} not available.\")\n",
    "\n",
    "    add_bullet_points(document, \"KEY TAKEAWAYS\", \"key_takeaways\")\n",
    "    add_bullet_points(document, \"FINANCIAL HIGHLIGHTS\", \"financial_highlights\")\n",
    "\n",
    "    # --- Footer ---\n",
    "    section = document.sections[0]\n",
    "    footer = section.footer\n",
    "    # Ensure there's at least one paragraph in the footer\n",
    "    if not footer.paragraphs:\n",
    "        footer.add_paragraph()\n",
    "    footer.paragraphs[0].text = \"Confidential - Norstella Internal Report\"\n",
    "    footer.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "    document.save(output_filename)\n",
    "    print(f\"Report '{output_filename}' generated successfully.\")"
   ],
   "id": "2d6a847c43e0c7bf",
   "outputs": [],
   "execution_count": 1193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T06:47:52.492261Z",
     "start_time": "2025-06-15T06:47:52.476992Z"
    }
   },
   "cell_type": "code",
   "source": "create_flash_report(report_data, \"Norstella_Q1_2025_Flash_Report.docx\")",
   "id": "d46bedd0a61e8950",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report 'Norstella_Q1_2025_Flash_Report.docx' generated successfully.\n"
     ]
    }
   ],
   "execution_count": 1194
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Add Q&A Recognition",
   "id": "3db37b4c541271f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instead of building the whole docx myself, i can populate an already created template by adding variables where I want the infromation added\n",
    "Need to go to the sharepoint and access flash reports.\n",
    "use"
   ],
   "id": "807fcb4dacc3ffa0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
